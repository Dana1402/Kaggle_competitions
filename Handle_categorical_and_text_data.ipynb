{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Handle categorical and text data",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dana1402/Kaggle_competitions/blob/main/Handle_categorical_and_text_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handle text features with many categories (50+) in Python"
      ],
      "metadata": {
        "id": "cEs6-UENcPnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as ps"
      ],
      "metadata": {
        "id": "6BwNUBkMcPnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Label Encoding**\n",
        "For ordinal or categorical features with a logical order:\n",
        "This converts each unique category into an integer.\n",
        "However, this may not work well for non-ordinal features\n",
        "as it can introduce unintended relationships between categories."
      ],
      "metadata": {
        "id": "BEbu_-whcPns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('')"
      ],
      "metadata": {
        "id": "49XJNg0ScPnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "df['encoded_feature'] = encoder.fit_transform(df['text_feature'])"
      ],
      "metadata": {
        "id": "jUG9ykbGcPnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. **One-Hot Encoding**\n",
        "For non-ordinal categorical features with many unique values:\n",
        "This creates binary columns for each unique category, but with 50+ categories,\n",
        "this can result in high-dimensional data, which may not be ideal."
      ],
      "metadata": {
        "id": "6y5SPu-ocPnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded_feature = encoder.fit_transform(df[['text_feature']])"
      ],
      "metadata": {
        "id": "rD1FbEYzcPnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. **Frequency/Count Encoding**\n",
        "You can replace each category with its frequency in the dataset:\n",
        "This helps preserve the information while keeping the feature one-dimensional."
      ],
      "metadata": {
        "id": "6HT__PyJcPnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['freq_encoded_feature'] = df['text_feature'].map(df['text_feature'].value_counts())"
      ],
      "metadata": {
        "id": "RDd7gOnFcPnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. **Target/Mean Encoding**\n",
        "For supervised learning, you can encode categories based on the mean of the target variable:\n",
        "This method introduces information from the target,\n",
        "making it more powerful but at risk of data leakage."
      ],
      "metadata": {
        "id": "PsZiclUNcPnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_encoded_feature = df.groupby('text_feature')['target'].mean()\n",
        "df['mean_encoded_feature'] = df['text_feature'].map(mean_encoded_feature)"
      ],
      "metadata": {
        "id": "l4GsOq4gcPnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. **Embedding Encoding** If you have large categorical features,\n",
        "you can use embedding techniques, commonly seen with deep learning models like neural networks:\n",
        "This approach is suitable for high-cardinality categorical features and can capture relationships between categories in a compact form."
      ],
      "metadata": {
        "id": "H9UA6-PBcPny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([ tf.keras.layers.Embedding(input_dim=num_categories, output_dim=embedding_dim) ])"
      ],
      "metadata": {
        "id": "B5sEZOpccPny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. **Hashing Encoding**\n",
        "A dimensionality-reduction technique that maps categories into a fixed number of hash buckets:\n",
        "This method works well when you need to reduce the dimensionality but maintain uniqueness."
      ],
      "metadata": {
        "id": "H0aCOBhQcPny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "hasher = FeatureHasher(n_features=10, input_type='string')\n",
        "hashed_feature = hasher.transform(df[['text_feature']].astype(str))"
      ],
      "metadata": {
        "id": "8jC8Dx2LcPny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lv9guVpCcPny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}